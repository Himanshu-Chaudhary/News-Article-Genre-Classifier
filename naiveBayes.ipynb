{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv , concat , DataFrame\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99a43ea78e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import the training data as chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/training.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._concatenate_chunks\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \"\"\"\n\u001b[1;32m    515\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import the training data as chunks\n",
    "dataFrame = read_csv('data/training.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHighestWordList():\n",
    "    location = 'data/training.csv'\n",
    "    length = 61189\n",
    "    data  = [np.empty([3000,61188]) for x in range(20)]\n",
    "    c = [0 for x in range(20)]\n",
    "    v = length -1\n",
    "    b = 1/v\n",
    "    \n",
    "    with open(location, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        count = 1\n",
    "        for row in reader:\n",
    "            label = int(row[length])-1\n",
    "            newData = row[1:length]\n",
    "            data[label][c[label]] = newData\n",
    "            c[label]+=1\n",
    "            count = count+1\n",
    "            if (count % 1000 == 0):\n",
    "                print(\"looping\")\n",
    "        print (\"done\")\n",
    "    f.close()    \n",
    "    data = [data[x][0:(c[x]+1)] for x in range(20)]\n",
    "    \n",
    "    total = [x.shape[0] for x in data]\n",
    "    totalWords = [np.sum(x) for x in data]\n",
    "    xCounts = np.empty([20,61188])\n",
    "    for i in range(20):\n",
    "        xCounts[i]=np.sum(data[i],axis=0)\n",
    "    py1 = total/np.sum(total)\n",
    "    pxy1 = np.array([(x[0]+b)/(x[1]+(b*length)) for x in zip(xCounts,totalWords)])\n",
    "    pxy = np.log2(pxy1)\n",
    "    py = np.log2(py1)\n",
    "    pxyt = pxy.transpose()\n",
    "    \n",
    "    xsum = xCounts.sum()\n",
    "    px = np.divide(np.add(1,xCounts).sum(axis=0),xsum)\n",
    "    \n",
    "    nw = ((pxy1.transpose()*py1).sum(axis=1))\n",
    "    nw1 = nw/(px)\n",
    "    \n",
    "    highestindex = np.argsort(-nw1).tolist()\n",
    "    \n",
    "    vocabname = \"data/vocabulary.txt\" \n",
    "    vocab = []\n",
    "    f = open(vocabname)\n",
    "    filecontents = f.readlines()\n",
    "    for line in filecontents:\n",
    "        vocab.append(line[0:-1])\n",
    "    print (\"done\")\n",
    "    \n",
    "    highestwords = [vocab[highestindex[i]] for i in range(100)]\n",
    "    print (highestwords)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "looping\n",
      "done\n",
      "done\n",
      "['wolverine', 'shipping', 'hulk', 'sale', 'sabretooth', 'comics', 'liefeld', 'hobgoblin', 'obo', 'bagged', 'spider', 'punisher', 'condition', 'forsale', 'ghost', 'offer', 'marvel', 'stereo', 'meg', 'scsi', 'manuals', 'rider', 'mint', 'art', 'cable', 'brand', 'motherboard', 'controller', 'drive', 'mhz', 'mb', 'mutants', 'panther', 'disks', 'cd', 'drives', 'pom', 'ide', 'monitor', 'modem', 'simms', 'floppy', 'keown', 'card', 'adapter', 'battery', 'ram', 'sony', 'printer', 'excellent', 'hz', 'disk', 'manual', 'price', 'cassette', 'cod', 'pin', 'hd', 'warranty', 'dx', 'mcfarlane', 'tape', 'offers', 'appears', 'selling', 'asking', 'mac', 'amp', 'nm', 'duo', 'bios', 'vf', 'bike', 'vga', 'lc', 'port', 'connector', 'items', 'sell', 'external', 'upgrade', 'board', 'sega', 'quadra', 'app', 'geoffrey', 'cpu', 'fpu', 'cards', 'prices', 'annual', 'dod', 'video', 'slot', 'car', 'audio', 'appearance', 'docs', 'cache', 'centris']\n"
     ]
    }
   ],
   "source": [
    "getHighestWordList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(traindf, testdf, validating = False, beta = 1): \n",
    "    trainingLabels = traindf.iloc[:,-1].values\n",
    "    validatingLabels = testdf.iloc[:,-1].values\n",
    "    validatingLabelsNames = testdf.iloc[:,0].values\n",
    "    validatingSet = dict([list(a) for a in zip(validatingLabelsNames, validatingLabels)])\n",
    "    totalDocuments = len(trainingLabels)\n",
    "    totalValidationDocuments = len(validatingLabels)\n",
    "    \n",
    "    print(\"the length of trainningLabels is ====  \" + str(totalDocuments))\n",
    "    print(\"the length of ValidatingLabels is ====  \" + str(totalValidationDocuments))\n",
    "    \n",
    "    traindf.drop(traindf.columns[[-1,0]],axis = 1, inplace=True)\n",
    "    trainingClassCount = Counter()\n",
    "    for val in trainingLabels:\n",
    "        trainingClassCount[val] += 1\n",
    "    \n",
    "    allLabels = np.unique(trainingLabels)\n",
    "    totalClassCount = len(allLabels)\n",
    "    sortedClassCount = sorted(trainingClassCount.items())\n",
    "    classCount = [y for (x,y) in sortedClassCount]\n",
    "    #print(classCount)\n",
    "    logPriorProb = [math.log(x/totalDocuments) for x in classCount]\n",
    "    trainingMatrix = np.array(traindf.values)\n",
    "    totalWords = len(trainingMatrix[0])\n",
    "   \n",
    "    dividedOnClass = [[x for x, y in zip(trainingMatrix,trainingLabels) if y == c] for c in allLabels]\n",
    "    tempTable = [np.array(val).sum(axis=0)for val in dividedOnClass]\n",
    "    smoother = beta if validating else 1 / totalWords\n",
    "    #print(smoother)\n",
    "    smoothCount = np.array(tempTable) + smoother\n",
    "    totalWordInEachClass = [sum(val) for val in tempTable]\n",
    "    totalWordInEachClassSmooth = np.array(totalWordInEachClass) + beta*totalWords\n",
    "    likelihood = np.array([ x / y for x , y in zip (smoothCount,totalWordInEachClassSmooth)])\n",
    "    logLikelihood = np.array([np.log(val) for val in likelihood])\n",
    "    \n",
    "    \n",
    "    testingDataFrame = testdf.iloc[:, :-1] if validating else testdf\n",
    "    testingId = testingDataFrame.iloc[:,0].values\n",
    "    #pprint(testingDataFrame)\n",
    "    #print(testingId)\n",
    "    testingDataFrame.drop(testingDataFrame.columns[0,],axis=1,inplace=True)\n",
    "    testingVals = np.array(testingDataFrame.values)\n",
    "    #print(testingVals)\n",
    "    probEstimation = [logLikelihood.dot(val) for val in testingVals]\n",
    "    totalProbEstimation = [[x + y for x,y in zip(logPriorProb, val)] for val in probEstimation]\n",
    "    prediction = [val.index(max(val))+1 for val in totalProbEstimation]\n",
    "    csvData = [ [docId , p]  for docId,p in zip (testingId,prediction)]\n",
    "    if not(validating):\n",
    "        csvData = [['id','class']] + csvData\n",
    "        with open('data/submission.csv', 'w',newline='') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerows(csvData)\n",
    "    \n",
    "    return (validatingSet , dict(csvData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted, actual):    \n",
    "    predictiondict =  predicted\n",
    "    actualdict = actual\n",
    "    totalwords = len(predicted)\n",
    "    correct = 0\n",
    "    for key in actual.keys():\n",
    "        if actual.get(key) == predicted.get(key):\n",
    "            correct += 1\n",
    "    print(\"accuracy ==========\"+ str(correct/totalwords))\n",
    "    return (correct/totalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainningdf = read_csv('data/testing.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trndf, tstdf = train_test_split(dataFrame, test_size=0.2)\n",
    "\n",
    "#x = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5,1]\n",
    "x = np.arange(0.00001, 1, 0.02)\n",
    "x = [np.log(x) for xx in x]\n",
    "y =[]\n",
    "for beta in x:\n",
    "    validating, prediction = naiveBayes(traindf = trndf.copy(), testdf= tstdf.copy(), validating = True, beta = beta)\n",
    "    y.append(accuracy(predicted = prediction, actual = validating))\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#value saved after running the algorithm for 2 hours with 100 beta values.\n",
    "x = np.arange(0.00001, 1, 0.01)\n",
    "x = np.log10(x)\n",
    "y = [0.8566666666666667, 0.8658333333333333, 0.8675, 0.8675, 0.8670833333333333, 0.8675, 0.8691666666666666, 0.86875, \n",
    "0.86875, 0.8695833333333334, 0.8683333333333333, 0.8683333333333333, 0.8670833333333333, 0.8670833333333333, 0.8670833333333333,\n",
    "0.8666666666666667, 0.8666666666666667, 0.86625, 0.8654166666666666, 0.8654166666666666, 0.865, 0.865, 0.865, 0.865, \n",
    "0.8645833333333334, 0.8629166666666667, 0.8625, 0.8616666666666667, 0.8616666666666667, 0.8604166666666667, 0.86, 0.86, \n",
    "0.86, 0.86, 0.8595833333333334, 0.86, 0.8595833333333334, 0.8575, 0.8566666666666667, 0.85625, 0.8554166666666667,\n",
    "0.8545833333333334, 0.8533333333333334, 0.85375, 0.8541666666666666, 0.8545833333333334, 0.8541666666666666, 0.8533333333333334,\n",
    "0.8525, 0.8520833333333333, 0.8516666666666667, 0.8508333333333333, 0.8508333333333333, 0.8504166666666667, 0.85,\n",
    "0.8491666666666666, 0.8479166666666667, 0.8475, 0.8470833333333333, 0.84625, 0.8458333333333333, 0.8454166666666667, \n",
    "0.8454166666666667, 0.8454166666666667, 0.845, 0.845, 0.8445833333333334, 0.84375, 0.8433333333333334, 0.8433333333333334, \n",
    "0.8433333333333334, 0.8433333333333334, 0.8429166666666666, 0.8420833333333333, 0.8404166666666667, 0.84, 0.84, \n",
    "0.8404166666666667, 0.8395833333333333, 0.8391666666666666, 0.8391666666666666, 0.8375, 0.8375, 0.8375, 0.8370833333333333, \n",
    "0.8366666666666667, 0.8358333333333333, 0.8358333333333333, 0.8354166666666667, 0.8354166666666667, 0.8354166666666667, \n",
    "0.8354166666666667, 0.8354166666666667, 0.8345833333333333, 0.8341666666666666, 0.8333333333333334, 0.8329166666666666, \n",
    "0.8325, 0.8316666666666667, 0.83125]\n",
    "\n",
    "print(len(y))\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusuion matrix\n",
    "\n",
    "def confusionMatrix(actual, predicion):\n",
    "    classes = set(actual.values())\n",
    "    size = len(classes)\n",
    "    matrix = np.zeros(shape=(size,size))\n",
    "    \n",
    "    for k,v in prediction.items():\n",
    "         matrix[v-1][actual.get(k)-1] += 1\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMatrix = DataFrame(confusionMatrix(actual = validating, predicion = prediction))\n",
    "print(dataFrame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          3.31662479  4.58257569  5.56776436  6.40312424  7.14142843\n",
      "  7.81024968  8.42614977  9.          9.53939201 10.04987562 10.53565375\n",
      " 11.         11.44552314 11.87434209 12.28820573 12.68857754 13.07669683\n",
      " 13.45362405 13.82027496 14.17744688 14.52583905 14.86606875 15.19868415\n",
      " 15.5241747  15.84297952 16.15549442 16.46207763 16.76305461 17.05872211\n",
      " 17.34935157 17.63519209 17.91647287 18.1934054  18.46618531 18.734994\n",
      " 19.         19.26136028 19.5192213  19.77371993 20.02498439 20.27313493\n",
      " 20.51828453 20.76053949 21.         21.23676058 21.47091055 21.70253441\n",
      " 21.9317122  22.15851981]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1, 500, 10)\n",
    "x = np.sqrt(x)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Saved values of y from running the algorithm on a list of beta => x = np.arange(0.00001, 1, 0.01)\n",
    "\n",
    "   ''' y = [0.8566666666666667, 0.8658333333333333, 0.8675, 0.8675, 0.8670833333333333, 0.8675, 0.8691666666666666, 0.86875, \n",
    "0.86875, 0.8695833333333334, 0.8683333333333333, 0.8683333333333333, 0.8670833333333333, 0.8670833333333333, 0.8670833333333333,\n",
    "0.8666666666666667, 0.8666666666666667, 0.86625, 0.8654166666666666, 0.8654166666666666, 0.865, 0.865, 0.865, 0.865, \n",
    "0.8645833333333334, 0.8629166666666667, 0.8625, 0.8616666666666667, 0.8616666666666667, 0.8604166666666667, 0.86, 0.86, \n",
    "0.86, 0.86, 0.8595833333333334, 0.86, 0.8595833333333334, 0.8575, 0.8566666666666667, 0.85625, 0.8554166666666667,\n",
    "0.8545833333333334, 0.8533333333333334, 0.85375, 0.8541666666666666, 0.8545833333333334, 0.8541666666666666, 0.8533333333333334,\n",
    "0.8525, 0.8520833333333333, 0.8516666666666667, 0.8508333333333333, 0.8508333333333333, 0.8504166666666667, 0.85,\n",
    "0.8491666666666666, 0.8479166666666667, 0.8475, 0.8470833333333333, 0.84625, 0.8458333333333333, 0.8454166666666667, \n",
    "0.8454166666666667, 0.8454166666666667, 0.845, 0.845, 0.8445833333333334, 0.84375, 0.8433333333333334, 0.8433333333333334, \n",
    "0.8433333333333334, 0.8433333333333334, 0.8429166666666666, 0.8420833333333333, 0.8404166666666667, 0.84, 0.84, \n",
    "0.8404166666666667, 0.8395833333333333, 0.8391666666666666, 0.8391666666666666, 0.8375, 0.8375, 0.8375, 0.8370833333333333, \n",
    "0.8366666666666667, 0.8358333333333333, 0.8358333333333333, 0.8354166666666667, 0.8354166666666667, 0.8354166666666667, \n",
    "0.8354166666666667, 0.8354166666666667, 0.8345833333333333, 0.8341666666666666, 0.8333333333333334, 0.8329166666666666, \n",
    "0.8325, 0.8316666666666667, 0.83125]''' \n",
    "\n",
    "#pprint(totalWordInEachClass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
